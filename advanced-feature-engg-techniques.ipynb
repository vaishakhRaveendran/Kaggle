{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. INTRODUCTION\n<center>\n<img src=\"https://cdn.pixabay.com/photo/2012/10/06/22/18/horse-60153_1280.jpg\" width=1300 height=1000 />\n</center>","metadata":{}},{"cell_type":"markdown","source":"**PROBLEM STATEMENT**\n\n<font size=\"3\"> We aim to predict the eventual outcome of horses based on various medical attributes and information. The target variable we want to predict is \"outcome,\" which represents what happened to the horse after medical treatment. The possible values for the outcome variable are</font>\n  \n1. <font size=\"3\">Lived</font>\n2. <font size=\"3\">Died</font>\n3. <font size=\"3\">Was Euthanized</font>\n\n<font size=\"3\">The dataset contains various attributes related to horses' medical conditions and treatments. Each attribute provides valuable information about the horse's health. Here is a brief description of the attributes:</font>\n\n1. **Surgery:** Whether the horse had surgery or was treated without surgery (Binary: 1 = Yes, 2 = No).\n2. **Age:** Age category of the horse (Binary: 1 = Adult, 2 = Young).\n3. **Hospital Number:** A unique numeric identifier for each horse's case.\n4. **Rectal Temperature:** The horse's rectal temperature in degrees Celsius.\n5. **Pulse:** The horse's heart rate in beats per minute.\n6. **Respiratory Rate:** The horse's respiratory rate.\n7. **Temperature of Extremities:** A subjective indication of peripheral circulation.\n8. **Peripheral Pulse:** Subjective assessment of peripheral pulse.\n9. **Mucous Membranes:** A subjective measurement of mucous membrane color.\n10. **Capillary Refill Time:** Clinical judgment of capillary refill time.\n11. **Pain:** Subjective assessment of the horse's pain level.\n12. **Peristalsis:** An indication of gut activity.\n13. **Abdominal Distension:** Severity of abdominal distension.\n14. **Nasogastric Tube:** Presence of gas in the nasogastric tube.\n15. **Nasogastric Reflux:** Amount of nasogastric reflux.\n16. **Nasogastric Reflux pH:** pH level of nasogastric reflux.\n17. **Rectal Examination - Feces:** Assessment of feces during rectal examination.\n18. **Abdomen:** Assessment of the horse's abdomen.\n19. **Packed Cell Volume:** The number of red cells in the blood by volume.\n20. **Total Protein:** Total protein level in the blood.\n21. **Abdominocentesis Appearance:** Appearance of fluid obtained from the abdominal cavity.\n22. **Abdominocentesis Total Protein:** Total protein level in the abdominal fluid.\n23. **Outcome:** The target variable representing the eventual outcome of the horse (Multiclass: 1 = Lived, 2 = Died, 3 = Euthanized).\n24. **Surgical Lesion:** Whether the problem was surgical or not (Binary: 1 = Yes, 2 = No).\n25. **25-27. Type of Lesion:** Information about the site, type, subtype, and specific code of the lesion.\n28. **CP Data:** Whether pathology data is present for the case (Binary: 1 = Yes, 2 = No).\n\n<font size=\"3\">The original data using which the synthetic data was generated is available [here](https://www.kaggle.com/datasets/yasserh/horse-survival-dataset)</font>\n\n**METRIC OF EVALUATION:** <font size=\"2\">MICRO-AVERAGED F1 SCORE</font>\n\n","metadata":{}},{"cell_type":"markdown","source":"# 2. IMPORTS","metadata":{}},{"cell_type":"code","source":"import sklearn\nimport numpy as np\nimport os\nimport datetime\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport missingno as msno\nfrom prettytable import PrettyTable\n%matplotlib inline\nimport seaborn as sns\nsns.set(style='darkgrid', font_scale=1.4)\nfrom tqdm import tqdm\nfrom tqdm.notebook import tqdm as tqdm_notebook\ntqdm_notebook.get_lock().locks = []\n# !pip install sweetviz\n# import sweetviz as sv\nimport concurrent.futures\nfrom copy import deepcopy       \nfrom functools import partial\nfrom itertools import combinations\nimport random\nfrom random import randint, uniform\nimport gc\nfrom sklearn.feature_selection import f_classif\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler,PowerTransformer, FunctionTransformer\nfrom sklearn import metrics\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom itertools import combinations\nfrom sklearn.impute import SimpleImputer\nimport xgboost as xg\nfrom sklearn.model_selection import train_test_split,cross_val_score\nfrom sklearn.metrics import mean_squared_error,mean_squared_log_error, roc_auc_score, accuracy_score, f1_score, precision_recall_curve, log_loss\nfrom sklearn.cluster import KMeans\n!pip install yellowbrick\nfrom yellowbrick.cluster import KElbowVisualizer\n!pip install gap-stat\nfrom gap_statistic.optimalK import OptimalK\nfrom scipy import stats\nimport statsmodels.api as sm\nfrom scipy.stats import ttest_ind\nfrom scipy.stats import boxcox\nimport math\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.base import BaseEstimator, TransformerMixin\n!pip install optuna\nimport optuna\nimport xgboost as xgb\n!pip install catboost\n!pip install lightgbm --install-option=--gpu --install-option=\"--boost-root=C:/local/boost_1_69_0\" --install-option=\"--boost-librarydir=C:/local/boost_1_69_0/lib64-msvc-14.1\"\nimport lightgbm as lgb\n!pip install category_encoders\nfrom category_encoders import OneHotEncoder, OrdinalEncoder, CountEncoder, CatBoostEncoder\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier, GradientBoostingClassifier,ExtraTreesClassifier, AdaBoostClassifier\n!pip install -U imbalanced-learn\nfrom imblearn.ensemble import BalancedRandomForestClassifier\nfrom sklearn.datasets import make_classification\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom catboost import CatBoost, CatBoostRegressor, CatBoostClassifier\nfrom sklearn.svm import NuSVC, SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.impute import KNNImputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\nfrom catboost import Pool\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import PCA\nfrom sklearn.decomposition import TruncatedSVD\n\n# Suppress warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.pandas.set_option('display.max_columns',None)","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-18T02:41:04.009229Z","iopub.execute_input":"2023-09-18T02:41:04.009709Z","iopub.status.idle":"2023-09-18T02:42:35.66405Z","shell.execute_reply.started":"2023-09-18T02:41:04.009669Z","shell.execute_reply":"2023-09-18T02:42:35.662104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.1 LOAD DATA","metadata":{}},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/playground-series-s3e22/train.csv')\ntest=pd.read_csv('/kaggle/input/playground-series-s3e22/test.csv')\noriginal=pd.read_csv(\"/kaggle/input/horse-survival-dataset/horse.csv\")\n\ntrain.drop(columns=[\"id\"],inplace=True)\ntest.drop(columns=[\"id\"],inplace=True)\n\ntrain_copy=train.copy()\ntest_copy=test.copy()\noriginal_copy=original.copy()\n\noriginal[\"original\"]=1\n\ntrain[\"original\"]=0\ntest[\"original\"]=0\n\ntrain=pd.concat([train,original],axis=0)\ntrain.reset_index(inplace=True,drop=True)\ntrain.head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-18T02:42:35.667177Z","iopub.execute_input":"2023-09-18T02:42:35.667595Z","iopub.status.idle":"2023-09-18T02:42:35.762604Z","shell.execute_reply.started":"2023-09-18T02:42:35.667561Z","shell.execute_reply":"2023-09-18T02:42:35.760939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.2 MISSING VALUE CHECKS","metadata":{}},{"cell_type":"code","source":"table = PrettyTable()\n\ntable.field_names = ['Feature', 'Data Type', 'Train Missing %', 'Test Missing %',\"Original Missing%\"]\nfor column in train_copy.columns:\n    data_type = str(train_copy[column].dtype)\n    non_null_count_train= np.round(100-train_copy[column].count()/train_copy.shape[0]*100,1)\n    if column!='outcome':\n        non_null_count_test = np.round(100-test_copy[column].count()/test_copy.shape[0]*100,1)\n    else:\n        non_null_count_test=\"NA\"\n    non_null_count_orig= np.round(100-original_copy[column].count()/original_copy.shape[0]*100,1)\n    table.add_row([column, data_type, non_null_count_train,non_null_count_test,non_null_count_orig])\nprint(table)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-18T02:42:35.764623Z","iopub.execute_input":"2023-09-18T02:42:35.76498Z","iopub.status.idle":"2023-09-18T02:42:35.803674Z","shell.execute_reply.started":"2023-09-18T02:42:35.764951Z","shell.execute_reply":"2023-09-18T02:42:35.801831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"msno.matrix(original_copy, color=  (0.4, 0.76, 0.65))\nplt.title(\"Original Data Missing Value Matrix\", fontsize=16)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-18T02:42:35.810001Z","iopub.execute_input":"2023-09-18T02:42:35.810465Z","iopub.status.idle":"2023-09-18T02:42:36.986954Z","shell.execute_reply.started":"2023-09-18T02:42:35.810431Z","shell.execute_reply":"2023-09-18T02:42:36.985368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size=\"3\">Not so many missing values, hence can be imputed. Original Data Set has more missing values, maybe dropping rows that are 100% filled in train and missing in original can be considered</font>","metadata":{}},{"cell_type":"markdown","source":"# 3. EXPLORATORY DATA ANALYSIS","metadata":{}},{"cell_type":"markdown","source":"## 3.1 TARGET DISTRIBUTIONS","metadata":{}},{"cell_type":"code","source":"def plot_pie_chart(data, title, ax):\n    data_counts = data['outcome'].value_counts()\n    labels = data_counts.index\n    sizes = data_counts.values\n    colors = [ (0.4, 0.76, 0.65), 'crimson',  (0.99, 0.55, 0.38)]  \n    explode = (0.1, 0, 0)  \n\n    ax.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=140)\n    ax.axis('equal') \n    ax.set_title(title)\n\nfig, axes = plt.subplots(1, 3, figsize=(18, 6))  # Create three subplots in a row\n\nplot_pie_chart(train, \"Train Target Distribution\", axes[0])\nplot_pie_chart(original, \"Original Target Distribution\", axes[1])\nplot_pie_chart(original.dropna(), \"Original Without NaN Target Distribution\", axes[2])\n\nplt.tight_layout()\nplt.show()\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-18T02:42:36.989169Z","iopub.execute_input":"2023-09-18T02:42:36.989796Z","iopub.status.idle":"2023-09-18T02:42:37.741018Z","shell.execute_reply.started":"2023-09-18T02:42:36.989742Z","shell.execute_reply":"2023-09-18T02:42:37.739357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size=\"3\">The Train data has less \"lived\" categories thatn the original data. However after dropping NaNs, Train and Original became really close in their distributions</font>","metadata":{}},{"cell_type":"markdown","source":"## 3.2 Numerical Feature Distributions","metadata":{}},{"cell_type":"code","source":"cont_cols = [f for f in train.columns if train[f].dtype != 'O' and train[f].nunique() > 2]\nn_rows = len(cont_cols)\nfig, axs = plt.subplots(n_rows, 2, figsize=(12, 4 * n_rows))\nsns.set_palette(\"Set2\")\nfor i, col in enumerate(cont_cols):\n    sns.violinplot(x='outcome', y=col, data=train_copy, ax=axs[i, 0])\n    axs[i, 0].set_title(f'{col.title()} Distribution by Target (Train)', fontsize=14)\n    axs[i, 0].set_xlabel('outcome', fontsize=12)\n    axs[i, 0].set_ylabel(col.title(), fontsize=12)\n    sns.despine()\n\n    sns.violinplot(x='outcome', y=col, data=original, ax=axs[i, 1])\n    axs[i, 1].set_title(f'{col.title()} Distribution by Target (Original)', fontsize=14)\n    axs[i, 1].set_xlabel('outcome', fontsize=12)\n    axs[i, 1].set_ylabel(col.title(), fontsize=12)\n    sns.despine()\n\nfig.tight_layout()\n\nplt.show()\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-18T02:42:37.743262Z","iopub.execute_input":"2023-09-18T02:42:37.744291Z","iopub.status.idle":"2023-09-18T02:42:45.221855Z","shell.execute_reply.started":"2023-09-18T02:42:37.744226Z","shell.execute_reply":"2023-09-18T02:42:45.220331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**INFERENCES**\n1. <font size=\"3\">Features seem to have distinguishable differences across numerical features especially Lesion_2.</font>\n2. <font size=\"3\">Differentiatiing between Euthanized and Lived might be difficult</font>","metadata":{}},{"cell_type":"markdown","source":"## 3.3 Numerical Pair Plots","metadata":{}},{"cell_type":"code","source":"sns.set(font_scale=0.95)\nplt.figure(figsize=(18, 10))\nsns.set(style=\"ticks\", color_codes=True)\nsns.pairplot(data=train_copy, vars=cont_cols,diag_kind='kde', \n        kind='scatter', palette='muted', \n        plot_kws={'s': 20}, hue='outcome')\nplt.show()\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-18T02:42:45.223692Z","iopub.execute_input":"2023-09-18T02:42:45.224107Z","iopub.status.idle":"2023-09-18T02:43:41.736643Z","shell.execute_reply.started":"2023-09-18T02:42:45.224073Z","shell.execute_reply":"2023-09-18T02:43:41.734575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**INFERENCES**\n1. <font size=\"3\">Increase in packed cell size increases died/euthanized horses. Also, lesion1 & 2 might have good correlation</font>\n2. <font size=\"3\">Total Protein seems clear distinction between died horses and others which is understandable because naturally died might be old with less protein %</font>\n3. <font size=\"3\">We will be trying a systematic way to create new features</font>","metadata":{}},{"cell_type":"markdown","source":"## 3.4 Categorical Features Analysis","metadata":{}},{"cell_type":"markdown","source":"<font size=\"3\">Few of the numerical columns that are discrete have been included in the categorical list</font>","metadata":{}},{"cell_type":"code","source":"cat_cols = [f for f in train.columns if (train[f].dtype != 'O' and train[f].nunique() / train.shape[0] < 0.1) or (train[f].dtype == 'O' and f not in ['outcome'])]\ncustom_palette = sns.color_palette(\"Set3\") \nfor col in cat_cols:\n    contingency_table = pd.crosstab(train[col], train['outcome'], normalize='index')\n    sns.set(style=\"whitegrid\")\n    contingency_table.plot(kind=\"bar\", stacked=True, color=sns.color_palette(\"Set2\") ,figsize=(20, 4))\n    plt.title(f\"Percentage Distribution of Target across {col}\")\n    plt.xlabel(col)\n    plt.ylabel(\"Percentage\")\n    plt.legend(title=\"Target Class\")\n    plt.show()\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-18T02:43:41.738999Z","iopub.execute_input":"2023-09-18T02:43:41.739443Z","iopub.status.idle":"2023-09-18T02:44:02.787343Z","shell.execute_reply.started":"2023-09-18T02:43:41.73941Z","shell.execute_reply":"2023-09-18T02:44:02.786029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**INFERENCES**\n1. <font size=\"3\">Pain is a good feature and I like pain :)</font>\n1. <font size=\"3\">Lesion 2 has reduna=dant classes 3112, 6112, 7111. All of them can be combined. Similarly the case for lesion 1</font>","metadata":{}},{"cell_type":"markdown","source":"# 4. Handle Missing Values","metadata":{}},{"cell_type":"markdown","source":"<font size=\"3\">Please refer my [notebook](https://www.kaggle.com/code/arunklenin/ps3e15-iterative-catboost-imputer-ensemble) for more details about Imputation Algorithm</font>","metadata":{}},{"cell_type":"code","source":"train_missing_percentage = (train.isnull().sum(axis=1) / len(train.columns)) * 100\ntest_missing_percentage = (test.isnull().sum(axis=1) / len(test.columns)) * 100\n\ntrain_result_dict = {}\ntest_result_dict = {}\nfor i in range(len(train_missing_percentage)):\n    num_missing_values = round(train.isnull().sum(axis=1).iloc[i])\n    if num_missing_values not in train_result_dict:\n        train_result_dict[num_missing_values] = 0\n    \n    train_result_dict[num_missing_values] += 1\nfor i in range(len(test_missing_percentage)):\n    num_missing_values = round(test.isnull().sum(axis=1).iloc[i])\n    if num_missing_values not in test_result_dict:\n        test_result_dict[num_missing_values] = 0\n    \n    test_result_dict[num_missing_values] += 1\ntotal_rows_train = len(train)\ntotal_rows_test = len(test)\n\nfor key in train_result_dict:\n    train_result_dict[key] = (train_result_dict[key] / total_rows_train) * 100\n\nfor key in test_result_dict:\n    test_result_dict[key] = (test_result_dict[key] / total_rows_test) * 100\n\n# Sort the dictionaries by keys\ntrain_result_dict = dict(sorted(train_result_dict.items()))\ntest_result_dict = dict(sorted(test_result_dict.items()))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-18T02:44:02.789276Z","iopub.execute_input":"2023-09-18T02:44:02.792963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_keys, train_values = zip(*train_result_dict.items())\ntest_keys, test_values = zip(*test_result_dict.items())\ncommon_keys = sorted(set(train_keys) | set(test_keys))\n\ntrain_values = [train_result_dict.get(key, 0) for key in common_keys]\ntest_values = [-test_result_dict.get(key, 0) for key in common_keys]\n\ny_values = np.arange(len(common_keys), 0, -1) - 1\n\nfig, ax = plt.subplots(figsize=(8, 12))\n# sns.set_palette(\"Set2\")\nax.barh(y_values, train_values, label='Train Dataset', color= (0.4, 0.76, 0.65))\nax.barh(y_values, test_values, label='Test Dataset', color=  (0.99, 0.55, 0.38))\nax.set_yticks(y_values)\nax.set_yticklabels(common_keys)\nax.set_xlabel('Percentage of Rows (%)')\nax.set_title(' Distributions of # of Missing Values per row')\nax.legend()\nplt.grid(axis='x', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size=\"3\">Let's delete any rows with missing more than 10 missing values per row in the train dataset</font>","metadata":{}},{"cell_type":"code","source":"missing_values_per_row = train.isna().sum(axis=1)\nprint(train.shape)\nthreshold = 10\ntrain = train[missing_values_per_row <= threshold]\nprint(train.shape)\ntrain=train.reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.1 Impute Categorical features","metadata":{}},{"cell_type":"code","source":"missing_cat=[f for f in train.columns if train[f].dtype==\"O\" and train[f].isna().sum()>0]\ntrain_missing_pct = train[missing_cat].isnull().mean() * 100\ntest_missing_pct = test[missing_cat].isnull().mean() * 100\n\nmissing_pct_df = pd.concat([train_missing_pct, test_missing_pct], axis=1, keys=['Train %', 'Test%'])\nprint(missing_pct_df)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_params={\n            'depth': 6,\n            'learning_rate': 0.1,\n            'l2_leaf_reg': 0.7,\n            'random_strength': 0.2,\n            'max_bin': 200,\n            'od_wait': 65,\n            'one_hot_max_size': 70,\n            'grow_policy': 'Depthwise',\n            'bootstrap_type': 'Bayesian',\n            'od_type': 'Iter',\n            'eval_metric': 'MultiClass',\n            'loss_function': 'MultiClass',\n}\ndef store_missing_rows(df, features):\n    missing_rows = {}\n    \n    for feature in features:\n        missing_rows[feature] = df[df[feature].isnull()]\n    \n    return missing_rows\n\ndef fill_missing_categorical(train, test, target, features, max_iterations=10):\n    df = pd.concat([train.drop(columns=target), test], axis=\"rows\")\n    df = df.reset_index(drop=True)\n\n    # Step 1: Store the instances with missing values in each feature\n    missing_rows = store_missing_rows(df, features)\n\n    # Step 2: Initially fill all missing values with \"Missing\"\n    for f in features:\n        df[f] = df[f].fillna(\"Missing_\" + f)\n\n    for iteration in tqdm(range(max_iterations), desc=\"Iterations\"):\n        for feature in features:\n            # Skip features with no missing values\n            rows_miss = missing_rows[feature].index\n\n            missing_temp = df.loc[rows_miss].copy()\n            non_missing_temp = df.drop(index=rows_miss).copy()\n            missing_temp = missing_temp.drop(columns=[feature])\n\n            other_features = [x for x in df.columns if x != feature and df[x].dtype == \"O\"]\n\n            X_train = non_missing_temp.drop(columns=[feature])\n            y_train = non_missing_temp[[feature]]\n\n            catboost_classifier = CatBoostClassifier(**cat_params)\n            catboost_classifier.fit(X_train, y_train, cat_features=other_features, verbose=False)\n\n            # Step 4: Predict missing values for the feature and update all N features\n            y_pred = catboost_classifier.predict(missing_temp)\n            \n            # Convert y_pred to strings if necessary\n            if y_pred.dtype != \"O\":\n                y_pred = y_pred.astype(str)\n\n            df.loc[rows_miss, feature] = y_pred\n\n    train[features] = np.array(df.iloc[:train.shape[0]][features])\n    test[features] = np.array(df.iloc[train.shape[0]:][features])\n\n    return train, test\n\ntrain, test = fill_missing_categorical(train, test, \"outcome\", missing_cat, 5)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.2 Impute Numerical Features","metadata":{}},{"cell_type":"code","source":"missing_num=[f for f in train.columns if train[f].dtype!=\"O\" and train[f].isna().sum()>0]\ntrain_missing_pct = train[missing_num].isnull().mean() * 100\ntest_missing_pct = test[missing_num].isnull().mean() * 100\nmissing_pct_df = pd.concat([train_missing_pct, test_missing_pct], axis=1, keys=['Train %', 'Test%'])\nprint(missing_pct_df)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cb_params = {\n            'iterations': 500,\n            'depth': 6,\n            'learning_rate': 0.02,\n            'l2_leaf_reg': 0.5,\n            'random_strength': 0.2,\n            'max_bin': 150,\n            'od_wait': 80,\n            'one_hot_max_size': 70,\n            'grow_policy': 'Depthwise',\n            'bootstrap_type': 'Bayesian',\n            'od_type': 'IncToDec',\n            'eval_metric': 'RMSE',\n            'loss_function': 'RMSE',\n            'random_state': 42,\n        }\ndef rmse(y1,y2):\n    return(np.sqrt(mean_squared_error(y1,y2)))\n\ndef fill_missing_numerical(train,test,target, features, max_iterations=10):\n    train_temp=train.copy()\n    if target in train_temp.columns:\n        train_temp=train_temp.drop(columns=target)\n        \n    \n    df=pd.concat([train_temp,test],axis=\"rows\")\n    df=df.reset_index(drop=True)\n    \n    # Step 1: Store the instances with missing values in each feature\n    missing_rows = store_missing_rows(df, features)\n    \n    # Step 2: Initially fill all missing values with \"Missing\"\n    for f in features:\n        df[f]=df[f].fillna(df[f].mean())\n    \n    cat_features=[f for f in df.columns if not pd.api.types.is_numeric_dtype(df[f])]\n    dictionary = {feature: [] for feature in features}\n    \n    for iteration in tqdm(range(max_iterations), desc=\"Iterations\"):\n        for feature in features:\n            # Skip features with no missing values\n            rows_miss = missing_rows[feature].index\n            \n            missing_temp = df.loc[rows_miss].copy()\n            non_missing_temp = df.drop(index=rows_miss).copy()\n            y_pred_prev=missing_temp[feature]\n            missing_temp = missing_temp.drop(columns=[feature])\n            \n            \n            # Step 3: Use the remaining features to predict missing values using Random Forests\n            X_train = non_missing_temp.drop(columns=[feature])\n            y_train = non_missing_temp[[feature]]\n            \n            catboost_classifier = CatBoostRegressor(**cb_params)\n            catboost_classifier.fit(X_train, y_train,cat_features=cat_features, verbose=False)\n            \n            # Step 4: Predict missing values for the feature and update all N features\n            y_pred = catboost_classifier.predict(missing_temp)\n            df.loc[rows_miss, feature] = y_pred\n            error_minimize=rmse(y_pred,y_pred_prev)\n            dictionary[feature].append(error_minimize)  # Append the error_minimize value\n\n    for feature, values in dictionary.items():\n        iterations = range(1, len(values) + 1)  # x-axis values (iterations)\n        plt.plot(iterations, values, label=feature)  # plot the values\n        plt.xlabel('Iterations')\n        plt.ylabel('RMSE')\n        plt.title('Minimization of RMSE with iterations')\n        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n    plt.show()\n    train[features] = np.array(df.iloc[:train.shape[0]][features])\n    test[features] = np.array(df.iloc[train.shape[0]:][features])\n\n    return train,test\n\n\ntrain,test = fill_missing_numerical(train,test,\"outcome\",missing_num,5)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"### Basic Functions","metadata":{}},{"cell_type":"code","source":"target_map={\n    \"lived\":0,\n    \"died\": 1,\n    \"euthanized\":2\n}     \n\ndef encode(y,target_map):\n    y=np.array(y)\n    encoded_y=[target_map[f] for f in y]\n    return encoded_y\ndef decode(y,target_map):\n    y=np.array(y)\n    reverse_dict={v: k for k, v in target_map.items()}\n    decoded_y=[reverse_dict[f] for f in y]\n    return decoded_y\ndef min_max_scaler(train, test, column):\n    \n    sc=MinMaxScaler()\n    \n    max_val=max(train[column].max(),test[column].max())\n    min_val=min(train[column].min(),test[column].min())\n\n    train[column]=(train[column]-min_val)/(max_val-min_val)\n    test[column]=(test[column]-min_val)/(max_val-min_val)\n    \n    return train,test  \ndef OHE(train_df,test_df,cols,target):\n    combined = pd.concat([train_df, test_df], axis=0)\n    for col in cols:\n        one_hot = pd.get_dummies(combined[col])\n        counts = combined[col].value_counts()\n        min_count_category = counts.idxmin()\n        one_hot = one_hot.drop(min_count_category, axis=1)\n        one_hot.columns=[str(f)+col for f in one_hot.columns]\n        combined = pd.concat([combined, one_hot], axis=\"columns\")\n        combined = combined.loc[:, ~combined.columns.duplicated()]\n    \n    # split back to train and test dataframes\n    train_ohe = combined[:len(train_df)]\n    test_ohe = combined[len(train_df):]\n    test_ohe.reset_index(inplace=True,drop=True)\n    test_ohe.drop(columns=[target],inplace=True)\n    return train_ohe, test_ohe","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.1 Numerical Transformations","metadata":{}},{"cell_type":"markdown","source":"<font size=\"3\">We're going to see what transformation works better for each feature and select them, the idea is to compress the data. There could be situations where you will have to stretch the data. These are the methods applied:</font>\n\n1. **Log Transformation**: <font size=\"3\">This transformation involves taking the logarithm of each data point. It is useful when the data is highly skewed and the variance increases with the mean.</font>\n                y = log(x)\n\n2. **Square Root Transformation**: <font size=\"3\">This transformation involves taking the square root of each data point. It is useful when the data is highly skewed and the variance increases with the mean.</font>\n                y = sqrt(x)\n\n3. **Box-Cox Transformation**: <font size=\"3\">This transformation is a family of power transformations that includes the log and square root transformations as special cases. It is useful when the data is highly skewed and the variance increases with the mean.</font>\n                y = [(x^lambda) - 1] / lambda if lambda != 0\n                y = log(x) if lambda = 0\n\n4. **Yeo-Johnson Transformation**: <font size=\"3\">This transformation is similar to the Box-Cox transformation, but it can be applied to both positive and negative values. It is useful when the data is highly skewed and the variance increases with the mean.</font>\n                y = [(|x|^lambda) - 1] / lambda if x >= 0, lambda != 0\n                y = log(|x|) if x >= 0, lambda = 0\n                y = -[(|x|^lambda) - 1] / lambda if x < 0, lambda != 2\n                y = -log(|x|) if x < 0, lambda = 2\n\n5. **Power Transformation**: <font size=\"3\">This transformation involves raising each data point to a power. It is useful when the data is highly skewed and the variance increases with the mean. The power can be any value, and is often determined using statistical methods such as the Box-Cox or Yeo-Johnson transformations.</font>\n                y = [(x^lambda) - 1] / lambda if method = \"box-cox\" and lambda != 0\n                y = log(x) if method = \"box-cox\" and lambda = 0\n                y = [(x + 1)^lambda - 1] / lambda if method = \"yeo-johnson\" and x >= 0, lambda != 0\n                y = log(x + 1) if method = \"yeo-johnson\" and x >= 0, lambda = 0\n                y = [-(|x| + 1)^lambda - 1] / lambda if method = \"yeo-johnson\" and x < 0, lambda != 2\n                y = -log(|x| + 1) if method = \"yeo-johnson\" and x < 0, lambda = 2","metadata":{}},{"cell_type":"code","source":"cont_cols = [f for f in train.columns if pd.api.types.is_numeric_dtype(train[f]) and train[f].nunique() / train.shape[0] * 100 > 2.5]\n\nsc=MinMaxScaler()\n\nglobal unimportant_features\nglobal overall_best_score\nglobal overall_best_col\nunimportant_features=[]\noverall_best_score=0\noverall_best_col='none'\n\nfor col in cont_cols:\n     train, test=min_max_scaler(train, test, col)\n\ndef transformer(train, test,cont_cols, target):\n    global unimportant_features\n    global overall_best_score\n    global overall_best_col\n    train_copy = train.copy()\n    test_copy = test.copy()\n    table = PrettyTable()\n    table.field_names = ['Feature', 'Original F1', 'Transformation', 'Tranformed F1']\n\n    for col in cont_cols:\n        \n        for c in [\"log_\"+col, \"sqrt_\"+col, \"bx_cx_\"+col, \"y_J_\"+col, \"log_sqrt\"+col, \"pow_\"+col, \"pow2_\"+col]:\n            if c in train_copy.columns:\n                train_copy = train_copy.drop(columns=[c])\n        \n        # Log Transformation after MinMax Scaling (keeps data between 0 and 1)\n        train_copy[\"log_\"+col] = np.log1p(train_copy[col])\n        test_copy[\"log_\"+col] = np.log1p(test_copy[col])\n        \n        # Square Root Transformation\n        train_copy[\"sqrt_\"+col] = np.sqrt(train_copy[col])\n        test_copy[\"sqrt_\"+col] = np.sqrt(test_copy[col])\n        \n        # Box-Cox transformation\n        combined_data = pd.concat([train_copy[[col]], test_copy[[col]]], axis=0)\n        epsilon = 1e-5\n        transformer = PowerTransformer(method='box-cox')\n        scaled_data = transformer.fit_transform(combined_data + epsilon)\n\n        train_copy[\"bx_cx_\" + col] = scaled_data[:train_copy.shape[0]]\n        test_copy[\"bx_cx_\" + col] = scaled_data[train_copy.shape[0]:]\n        # Yeo-Johnson transformation\n        transformer = PowerTransformer(method='yeo-johnson')\n        train_copy[\"y_J_\"+col] = transformer.fit_transform(train_copy[[col]])\n        test_copy[\"y_J_\"+col] = transformer.transform(test_copy[[col]])\n        \n        # Power transformation, 0.25\n        power_transform = lambda x: np.power(x + 1 - np.min(x), 0.25)\n        transformer = FunctionTransformer(power_transform)\n        train_copy[\"pow_\"+col] = transformer.fit_transform(train_copy[[col]])\n        test_copy[\"pow_\"+col] = transformer.transform(test_copy[[col]])\n        \n        # Power transformation, 2\n        power_transform = lambda x: np.power(x + 1 - np.min(x), 2)\n        transformer = FunctionTransformer(power_transform)\n        train_copy[\"pow2_\"+col] = transformer.fit_transform(train_copy[[col]])\n        test_copy[\"pow2_\"+col] = transformer.transform(test_copy[[col]])\n        \n        # Log to power transformation\n        train_copy[\"log_sqrt\"+col] = np.log1p(train_copy[\"sqrt_\"+col])\n        test_copy[\"log_sqrt\"+col] = np.log1p(test_copy[\"sqrt_\"+col])\n        \n        temp_cols = [col, \"log_\"+col, \"sqrt_\"+col, \"bx_cx_\"+col, \"y_J_\"+col, \"log_sqrt\"+col, \"pow_\"+col, \"pow2_\"+col]\n        \n        train_copy[temp_cols] = train_copy[temp_cols].fillna(0)\n        test_copy[temp_cols] = test_copy[temp_cols].fillna(0)\n        \n        pca = TruncatedSVD(n_components=1)\n        x_pca_train = pca.fit_transform(train_copy[temp_cols])\n        x_pca_test = pca.transform(test_copy[temp_cols])\n        x_pca_train = pd.DataFrame(x_pca_train, columns=[col+\"_pca_comb\"])\n        x_pca_test = pd.DataFrame(x_pca_test, columns=[col+\"_pca_comb\"])\n        temp_cols.append(col+\"_pca_comb\")\n        \n        test_copy = test_copy.reset_index(drop=True)\n        \n        train_copy = pd.concat([train_copy, x_pca_train], axis='columns')\n        test_copy = pd.concat([test_copy, x_pca_test], axis='columns')\n        \n        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n        \n        f1_scores = []\n        \n        for f in temp_cols:\n            X = train_copy[[f]].values\n            y = train_copy[target].values\n            \n            f1 = []\n            for train_idx, val_idx in kf.split(X, y):\n                X_train, y_train = X[train_idx], y[train_idx]\n                x_val, y_val = X[val_idx], y[val_idx]\n                model =   SVC(gamma=\"auto\", probability=True, random_state=42)\n        \n                model.fit(X_train, encode(y_train, target_map))\n                y_pred = model.predict(x_val)\n                f1.append(f1_score(encode(y_val, target_map), y_pred, average='micro'))\n            f1_scores.append((f, np.mean(f1)))\n            \n            if overall_best_score < np.mean(f1):\n                overall_best_score = np.mean(f1)\n                overall_best_col = f\n\n            if f == col:\n                orig_mae = np.mean(f1)\n                \n        best_col, best_f1 = sorted(f1_scores, key=lambda x: x[1], reverse=True)[0]\n        cols_to_drop = [f for f in temp_cols if f != best_col and f not in col]\n        final_selection = [f for f in temp_cols if f not in cols_to_drop]\n        \n        if cols_to_drop:\n            unimportant_features = unimportant_features+cols_to_drop\n        table.add_row([col,orig_mae,best_col ,best_f1])\n    print(table)   \n    print(\"overall best CV RMSE score: \",overall_best_score)\n    return train_copy, test_copy\n\ntrain, test= transformer(train, test,cont_cols, \"outcome\")\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.2 Categorical Encoding","metadata":{}},{"cell_type":"markdown","source":"<font size=\"3\">For each categorical/discrete variable, perform the following encoding techniques:</font>\n\n\n* **Count/Frequency Encoding**: Count the number of occurrences of each category and replace the category with its count.\n* **Count Labeling**: Assign a label to each category based on its count, with higher counts receiving higher labels.\n* **Target-Guided Mean Encoding**: Rank the categories based on the mean of target column across each category\n* **One-Hot Encoding**: Apply OHE if the frequency is less than 15(avoid creating so many features)\n\nPlease note that the features a particular encoding technique is not selected only if it has superior technique and the correlation with that is high","metadata":{}},{"cell_type":"markdown","source":"## Pre-Processing","metadata":{}},{"cell_type":"code","source":"cat_cols = [f for f in train.columns if train[f].nunique() / train.shape[0] * 100 <= 5 and f not in ['outcome']+cont_cols+ unimportant_features]\n\n'''Combine categories with 100% target'''\nlesion2_map={\n    3112:3111,\n    6111:3111,\n    7112:3111\n}\ntrain['lesion_2']=train['lesion_2'].replace(lesion2_map)\ntest['lesion_2']=test['lesion_2'].replace(lesion2_map)\n\ntrain['pain']=train['pain'].replace({'moderate':'slight'})\ntest['pain']=test['pain'].replace({'moderate':'slight'})\nfor col in cat_cols:\n    if train[col].dtype==\"O\":\n        train[col]=train[col].astype(str)+\"_\"+col\n        test[col]=test[col].astype(str)+\"_\"+col","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef cat_encoding(train, test, target):\n    global overall_best_score\n    global overall_best_col\n    table = PrettyTable()\n    table.field_names = ['Feature', 'Encoded Features', 'F1 Score']\n    train_copy=train.copy()\n    test_copy=test.copy()\n    train_dum = train.copy()\n    train_dum[target] = encode(train[target], target_map)\n    for feature in cat_cols:\n        cat_labels = train_dum.groupby([feature])[target].mean().sort_values().index\n        cat_labels2 = {k: i for i, k in enumerate(cat_labels, 0)}\n        train_copy[feature + \"_target\"] = train[feature].map(cat_labels2)\n        test_copy[feature + \"_target\"] = test[feature].map(cat_labels2)\n\n        dic = train[feature].value_counts().to_dict()\n        train_copy[feature + \"_count\"] =train[feature].map(dic)\n        test_copy[feature + \"_count\"] = test[feature].map(dic)\n\n        dic2=train[feature].value_counts().to_dict()\n        list1=np.arange(len(dic2.values()),0,-1) # Higher rank for high count\n        # list1=np.arange(len(dic2.values())) # Higher rank for low count\n        dic3=dict(zip(list(dic2.keys()),list1))\n        train_copy[feature+\"_count_label\"]=train[feature].replace(dic3).astype(float)\n        test_copy[feature+\"_count_label\"]=test[feature].replace(dic3).astype(float)\n\n        temp_cols = [feature + \"_target\", feature + \"_count\", feature + \"_count_label\"]\n\n        \n        if train_copy[feature].dtype=='O':\n            train_copy, test_copy = OHE(train_copy, test_copy, [feature], target)\n            train_copy=train_copy.drop(columns=[feature])\n            test_copy=test_copy.drop(columns=[feature])\n        else:\n            if train_copy[feature].nunique()<15:\n                train_copy[feature+\"_OHE\"]=train_copy[feature].astype(str)+\"_\"+feature\n                test_copy[feature+\"_OHE\"]=test_copy[feature].astype(str)+\"_\"+feature\n                train_copy, test_copy = OHE(train_copy, test_copy, [feature], target)\n                train_copy=train_copy.drop(columns=[feature+\"_OHE\"])\n                test_copy=test_copy.drop(columns=[feature+\"_OHE\"])\n                temp_cols.append(feature)\n            \n\n        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n\n        f1_scores = []\n\n        for f in temp_cols:\n            X = train_copy[[f]].values\n            y = train_copy[target].values\n\n            f1 = []\n            for train_idx, val_idx in kf.split(X, y):\n                X_train, y_train = X[train_idx], y[train_idx]\n                x_val, y_val = X[val_idx], y[val_idx]\n                model =  HistGradientBoostingClassifier (max_iter=300, learning_rate=0.02, max_depth=6, random_state=42)\n                model.fit(X_train, encode(y_train, target_map))\n                y_pred = model.predict(x_val)\n                f1.append(f1_score(encode(y_val, target_map), y_pred, average='micro'))\n            f1_scores.append((f, np.mean(f1)))\n            if overall_best_score < np.mean(f1):\n                overall_best_score = np.mean(f1)\n                overall_best_col = f\n        best_col, best_f1 = sorted(f1_scores, key=lambda x: x[1], reverse=True)[0]\n\n        corr = train_copy[temp_cols].corr(method='pearson')\n        corr_with_best_col = corr[best_col]\n        cols_to_drop = [f for f in temp_cols if corr_with_best_col[f] > 0.5 and f != best_col]\n        final_selection = [f for f in temp_cols if f not in cols_to_drop]\n        if cols_to_drop:\n            train_copy = train_copy.drop(columns=cols_to_drop)\n            test_copy = test_copy.drop(columns=cols_to_drop)\n\n        table.add_row([feature, final_selection, best_f1])\n\n    print(table)\n    print(\"overall best CV score: \", overall_best_score)\n    return train_copy, test_copy\n\ntrain, test= cat_encoding(train, test, \"outcome\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.3 Clustering","metadata":{}},{"cell_type":"markdown","source":"<font size=\"3\"> All the unimportant features that are not the best transformation technique are selected and applied a K-Means Clustering technique</font>","metadata":{}},{"cell_type":"code","source":"table = PrettyTable()\ntable.field_names = ['Clustered Feature', 'F1 (CV-TRAIN)']\nfor col in cont_cols:\n    sub_set=[f for f in unimportant_features if col in f]\n    temp_train=train[sub_set]\n    temp_test=test[sub_set]\n    sc=StandardScaler()\n    temp_train=sc.fit_transform(temp_train)\n    temp_test=sc.transform(temp_test)\n    model = KMeans()\n\n    # print(ideal_clusters)\n    kmeans = KMeans(n_clusters=25)\n    kmeans.fit(np.array(temp_train))\n    labels_train = kmeans.labels_\n\n    train[col+\"_unimp_cluster_WOE\"] = labels_train\n    test[col+\"_unimp_cluster_WOE\"] = kmeans.predict(np.array(temp_test))\n\n    \n    kf=KFold(n_splits=5, shuffle=True, random_state=42)\n    \n    X=train[[col+\"_unimp_cluster_WOE\"]].values\n    y=train[\"outcome\"].values\n\n    f1=[]\n    for train_idx, val_idx in kf.split(X,y):\n        X_train,y_train=X[train_idx],y[train_idx]\n        x_val,y_val=X[val_idx],y[val_idx]\n        model = HistGradientBoostingClassifier (max_iter=300, learning_rate=0.02, max_depth=6, random_state=42)\n        model.fit(X_train, encode(y_train, target_map))\n        y_pred = model.predict(x_val)\n        f1.append(f1_score(encode(y_val, target_map), y_pred, average='micro'))\n        \n    table.add_row([col+\"_unimp_cluster_WOE\",np.mean(f1)])\n    if overall_best_score<np.mean(f1):\n        overall_best_score=np.mean(f1)\n        overall_best_col=col+\"_unimp_cluster_WOE\"\n\nprint(table)\nprint(\"overall best CV score: \", overall_best_score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.4 Arithmetic New Features","metadata":{}},{"cell_type":"markdown","source":"<font size=\"3\">Until now, I have saved the best overall column and the best overall score, a few feature can be created based on the below criteria:</font>\n* New features are based on the existing features by computing the arithmetic combinations\n* The best arithmetic function is selected based on the individual performnace\n* If the best arithmetic feature has better f1 score than the overall best score or the correlation of this feature with the existing features is less than 0.9, then a new feature is added to the dataset. ","metadata":{}},{"cell_type":"code","source":"def better_features(train, test, target, cols, best_score):\n    new_cols = []\n    skf = KFold(n_splits=5, shuffle=True, random_state=42)  # Stratified k-fold object\n    best_list=[]\n    for i in tqdm(range(len(cols)), desc='Generating Columns'):\n        col1 = cols[i]\n        temp_df = pd.DataFrame()  # Temporary dataframe to store the generated columns\n        temp_df_test = pd.DataFrame()  # Temporary dataframe for test data\n\n        for j in range(i+1, len(cols)):\n            col2 = cols[j]\n            # Multiply\n            temp_df[col1 + '*' + col2] = train[col1] * train[col2]\n            temp_df_test[col1 + '*' + col2] = test[col1] * test[col2]\n\n            # Divide (col1 / col2)\n            temp_df[col1 + '/' + col2] = train[col1] / (train[col2] + 1e-5)\n            temp_df_test[col1 + '/' + col2] = test[col1] / (test[col2] + 1e-5)\n\n            # Divide (col2 / col1)\n            temp_df[col2 + '/' + col1] = train[col2] / (train[col1] + 1e-5)\n            temp_df_test[col2 + '/' + col1] = test[col2] / (test[col1] + 1e-5)\n\n            # Subtract\n            temp_df[col1 + '-' + col2] = train[col1] - train[col2]\n            temp_df_test[col1 + '-' + col2] = test[col1] - test[col2]\n\n            # Add\n            temp_df[col1 + '+' + col2] = train[col1] + train[col2]\n            temp_df_test[col1 + '+' + col2] = test[col1] + test[col2]\n\n        SCORES = []\n        for column in temp_df.columns:\n            scores = []\n            for train_index, val_index in skf.split(train, train[target]):\n                X_train, X_val = temp_df[column].iloc[train_index].values.reshape(-1, 1), temp_df[column].iloc[val_index].values.reshape(-1, 1)\n                y_train, y_val = train[target].iloc[train_index], train[target].iloc[val_index]\n                model = SVC(gamma=\"auto\", probability=True, random_state=42)\n                model.fit(X_train,  encode(y_train, target_map))\n                y_pred = model.predict(X_val)\n                score = f1_score( encode(y_val, target_map), y_pred, average='micro')\n                scores.append(score)\n            mean_score = np.mean(scores)\n            SCORES.append((column, mean_score))\n\n        if SCORES:\n            best_col, best_f1 = sorted(SCORES, key=lambda x: x[1],reverse=True)[0]\n            corr_with_other_cols = train.drop([target] + new_cols, axis=1).corrwith(temp_df[best_col])\n            if (corr_with_other_cols.abs().max() < 0.9 or best_f1 > best_score) and corr_with_other_cols.abs().max() !=1 :\n                train[best_col] = temp_df[best_col]\n                test[best_col] = temp_df_test[best_col]\n                new_cols.append(best_col)\n                print(f\"Added column '{best_col}' with F1 Score: {best_f1:.4f} & Correlation {corr_with_other_cols.abs().max():.4f}\")\n\n    return train, test, new_cols","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size=\"3\"> The above process is time consuming so we will apply that on selected features, the best 50</font>","metadata":{}},{"cell_type":"code","source":"# exist_cols = [f for f in train.columns if f not in ['outcome'] and train[f].nunique()>2]\n# top_features = {}\n# for f in exist_cols:\n#     kf = KFold(n_splits=5, shuffle=True, random_state=42)\n#     X = train[[f]].values\n#     y = train[\"outcome\"].values\n\n#     f1_scores= []\n#     for train_idx, val_idx in kf.split(X, y):\n#         X_train, y_train = X[train_idx], y[train_idx]\n#         X_val, y_val = X[val_idx], y[val_idx]\n\n#         model = SVC(gamma=\"auto\", probability=True, random_state=42)\n#         model.fit(X_train,  encode(y_train, target_map))\n#         y_pred = model.predict(X_val)\n#         score = f1_score( encode(y_val, target_map), y_pred, average='micro')\n#         f1_scores.append(score)\n#     avg_f1 = np.mean(f1_scores)\n#     top_features[f] = avg_f1\n\n# sorted_top_features = sorted(top_features.items(), key=lambda x: x[1],reverse=True)\n\n# top_50_features = [feature for feature, _ in sorted_top_features[:50]]\n# print(\"Top 50 features with the highest F1 :\")\n# print(top_50_features)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train, test,new_cols=better_features(train, test, 'outcome', top_50_features, overall_best_score)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size=\"3\">We don't have to run the above algorithm every time, we just can store the combinations and compute just the required columns</font>","metadata":{}},{"cell_type":"code","source":"new_cols=['packed_cell_volume_count_label*pain_count',\n 'packed_cell_volume_target-pow2_total_protein',\n 'packed_cell_volume+pulse_target',\n 'pulse+bx_cx_hospital_number',\n 'pulse_target*y_J_hospital_number',\n 'pulse_count+pow2_total_protein',\n 'lesion_1_count_label+bx_cx_hospital_number',\n 'pulse_count_label+pain_count',\n 'lesion_1_target*bx_cx_hospital_number',\n 'lesion_1/total_protein_unimp_cluster_WOE',\n 'abdomo_appearance_target/sqrt_hospital_number',\n 'pain_target/y_J_hospital_number',\n 'pain_count-hospital_number_unimp_cluster_WOE',\n 'pain_count_label/pow2_total_protein',\n 'bx_cx_hospital_number/capillary_refill_time_target',\n 'capillary_refill_time_count/bx_cx_hospital_number',\n 'capillary_refill_time_count_label*total_protein_pca_comb',\n 'peripheral_pulse_target/bx_cx_nasogastric_reflux_ph',\n 'abdominal_distention_count/nasogastric_reflux_ph_unimp_cluster_WOE',\n 'mucous_membrane_target*total_protein_pca_comb',\n 'mucous_membrane_count-total_protein_pca_comb',\n 'mucous_membrane_count_label+total_protein_pca_comb',\n 'respiratory_rate_unimp_cluster_WOE/log_hospital_number',\n 'abdominal_distention_target*total_protein_pca_comb',\n 'abdominal_distention_count*y_J_hospital_number',\n 'abdominal_distention_count_label/log_sqrthospital_number',\n 'total_protein_unimp_cluster_WOE*peristalsis_count',\n 'nasogastric_reflux_ph_pca_comb-peristalsis_count',\n 'peristalsis_target/hospital_number',\n 'peristalsis_count*hospital_number_pca_comb',\n 'peristalsis_count_label/hospital_number',\n 'rectal_temp_pca_comb/y_J_nasogastric_reflux_ph',\n 'y_J_nasogastric_reflux_ph/sqrt_hospital_number',\n 'pow2_total_protein/log_hospital_number',\n 'total_protein_pca_comb/y_J_rectal_temp',\n 'total_protein_pca_comb/bx_cx_total_protein',\n 'hospital_number_pca_comb/hospital_number',\n 'bx_cx_nasogastric_reflux_ph/bx_cx_rectal_temp',\n 'bx_cx_hospital_number/hospital_number',\n 'bx_cx_hospital_number/log_hospital_number',\n 'bx_cx_nasogastric_reflux_ph/sqrt_hospital_number',\n 'pow2_hospital_number/hospital_number_unimp_cluster_WOE',\n 'bx_cx_nasogastric_reflux_ph/log_sqrthospital_number',\n 'rectal_temp_unimp_cluster_WOE/bx_cx_hospital_number',\n 'rectal_temp_unimp_cluster_WOE/bx_cx_total_protein',\n 'bx_cx_total_protein/bx_cx_nasogastric_reflux_ph',\n 'hospital_number_unimp_cluster_WOE/bx_cx_nasogastric_reflux_ph']+['bx_cx_pulse_target*y_J_lesion_1_target',\n 'hospital_number-y_J_lesion_1_target',\n 'log_hospital_number-y_J_lesion_1_target',\n 'sqrt_hospital_number-y_J_lesion_1_target',\n 'bx_cx_hospital_number*y_J_lesion_1_target',\n 'y_J_hospital_number+y_J_lesion_1_target',\n 'y_J_lesion_1_target/pow_hospital_number',\n 'pow2_hospital_number-y_J_lesion_1_target',\n 'log_sqrthospital_number-y_J_lesion_1_target',\n 'hospital_number_pca_comb-y_J_lesion_1_target',\n 'bx_cx_pulse_count+pow2_abdomo_protein',\n 'y_J_packed_cell_volume_target+log_abdomo_protein',\n 'pulse_unimp_cluster_WOE-abdomo_protein',\n 'y_J_lesion_1_target*pow2_total_protein_target',\n 'y_J_lesion_1_count_label+abdomo_protein',\n 'packed_cell_volume+pain_target',\n 'log_packed_cell_volume-pain_target',\n 'sqrt_packed_cell_volume*pain_target',\n 'bx_cx_packed_cell_volume-pow_abdomo_protein',\n 'y_J_packed_cell_volume-pow_abdomo_protein',\n 'pow_packed_cell_volume*log_lesion_1',\n 'pow2_packed_cell_volume*pain_target',\n 'log_sqrtpacked_cell_volume*pain_target',\n 'packed_cell_volume_pca_comb-pain_count',\n 'y_J_packed_cell_volume_count_label/pain_target',\n 'pain_target/bx_cx_pulse_count_label',\n 'lesion_1+pain_target',\n 'log_lesion_1*pain_target',\n 'sqrt_lesion_1+pain_target',\n 'bx_cx_lesion_1/pow_abdomo_protein',\n 'y_J_lesion_1/pow_abdomo_protein',\n 'pow_lesion_1+pain_target',\n 'pow2_lesion_1/pain_count_label',\n 'log_sqrtlesion_1+pain_target',\n 'lesion_1_pca_comb+pain_target',\n 'pulse-y_J_lesion_1_count',\n 'pow2_pulse-y_J_lesion_1_count',\n 'log_pulse-y_J_lesion_1_count',\n 'sqrt_pulse-y_J_lesion_1_count',\n 'bx_cx_pulse*pain_count',\n 'pow_abdomo_protein/y_J_pulse',\n 'pow_pulse-y_J_lesion_1_count',\n 'log_sqrtpulse-y_J_lesion_1_count',\n 'pulse_pca_comb+pain_target',\n 'abdomo_appearance_target*pow2_total_protein_target',\n 'pain_target/pow_abdomo_protein',\n 'pain_count+abdomo_protein',\n 'pow_abdomo_protein/pain_count_label',\n 'y_J_lesion_1_count-abdomo_protein',\n 'pow2_total_protein_target/capillary_refill_time_target',\n 'capillary_refill_time_target/bx_cx_abdomo_protein',\n 'capillary_refill_time_count+abdomo_protein',\n 'capillary_refill_time_count_label+log_abdomo_protein',\n 'log_abdomo_protein/abdomo_protein']","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def apply_arithmetic_operations(train_df, test_df, expressions_list):\n    for expression in expressions_list:\n        if expression not in train_df.columns:\n            # Split the expression based on operators (+, -, *, /)\n            parts = expression.split('+') if '+' in expression else \\\n                    expression.split('-') if '-' in expression else \\\n                    expression.split('*') if '*' in expression else \\\n                    expression.split('/')\n\n            # Get the DataFrame column names involved in the operation\n            cols = [col for col in parts]\n\n            # Perform the corresponding arithmetic operation based on the operator in the expression\n            if cols[0] in train.columns and cols[1] in train.columns:\n                if '+' in expression:\n                    train_df[expression] = train_df[cols[0]] + train_df[cols[1]]\n                    test_df[expression] = test_df[cols[0]] + test_df[cols[1]]\n                elif '-' in expression:\n                    train_df[expression] = train_df[cols[0]] - train_df[cols[1]]\n                    test_df[expression] = test_df[cols[0]] - test_df[cols[1]]\n                elif '*' in expression:\n                    train_df[expression] = train_df[cols[0]] * train_df[cols[1]]\n                    test_df[expression] = test_df[cols[0]] * test_df[cols[1]]\n                elif '/' in expression:\n                    train_df[expression] = train_df[cols[0]] / (train_df[cols[1]]+1e-5)\n                    test_df[expression] = test_df[cols[0]] /( test_df[cols[1]]+1e-5)\n    \n    return train_df, test_df\n\ntrain, test = apply_arithmetic_operations(train, test, new_cols)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.5 Feature Elimination","metadata":{}},{"cell_type":"markdown","source":"**Steps to Eliminate Correlated Fruit Features:**\n\n* Group features based on their parent feature. For example, all features derived from pulse come under one set\n* Apply PCA on the set, Cluster-Target Encoding on the set\n* See the performance of each feature on a cross-validated single feature-target model\n* Select the feature with highest CV-MAE","metadata":{}},{"cell_type":"code","source":"first_drop=[ f for f in unimportant_features if f in train.columns]\ntrain=train.drop(columns=first_drop)\ntest=test.drop(columns=first_drop)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### It is evident that there would be NaN in test data as we have new values/categories in the test, so let's fill them before apply PCA. ","metadata":{}},{"cell_type":"code","source":"final_drop_list=[]\nmissing_num = [f for f in test.columns if (test[f].isna().sum() > 0).any()]\ntrain,test = fill_missing_numerical(train,test,\"outcome\",missing_num,5)\n\ntable = PrettyTable()\ntable.field_names = ['Original', 'Final Transformation', 'F1 CV']\nthreshold=0.95\n# It is possible that multiple parent features share same child features, so store selected features to avoid selecting the same feature again\nbest_cols=[]\n\nfor col in cont_cols:\n    sub_set=[f for f in train.columns if (str(col) in str(f)) and (train[f].nunique()>2)]\n#     print(sub_set)\n    if len(sub_set)>2:\n        correlated_features = []\n\n        for i, feature in enumerate(sub_set):\n            # Check correlation with all remaining features\n            for j in range(i+1, len(sub_set)):\n                correlation = np.abs(train[feature].corr(train[sub_set[j]]))\n                # If correlation is greater than threshold, add to list of highly correlated features\n                if correlation > threshold:\n                    correlated_features.append(sub_set[j])\n\n        # Remove duplicate features from the list\n        correlated_features = list(set(correlated_features))\n#         print(correlated_features)\n        if len(correlated_features)>=2:\n\n            temp_train=train[correlated_features]\n            temp_test=test[correlated_features]\n            #Scale before applying PCA\n            sc=StandardScaler()\n            temp_train=sc.fit_transform(temp_train)\n            temp_test=sc.transform(temp_test)\n\n            # Initiate PCA\n            pca=TruncatedSVD(n_components=1)\n            x_pca_train=pca.fit_transform(temp_train)\n            x_pca_test=pca.transform(temp_test)\n            x_pca_train=pd.DataFrame(x_pca_train, columns=[col+\"_pca_comb_final\"])\n            x_pca_test=pd.DataFrame(x_pca_test, columns=[col+\"_pca_comb_final\"])\n            train=pd.concat([train,x_pca_train],axis='columns')\n            test=pd.concat([test,x_pca_test],axis='columns')\n\n            # Clustering\n            model = KMeans()\n            kmeans = KMeans(n_clusters=10)\n            kmeans.fit(np.array(temp_train))\n            labels_train = kmeans.labels_\n\n            train[col+'_final_cluster'] = labels_train\n            test[col+'_final_cluster'] = kmeans.predict(np.array(temp_test))\n\n\n            correlated_features=correlated_features+[col+\"_pca_comb_final\",col+\"_final_cluster\"]\n\n            # See which transformation along with the original is giving you the best univariate fit with target\n            kf=KFold(n_splits=5, shuffle=True, random_state=42)\n\n            scores=[]\n\n            for f in correlated_features:\n                X=train[[f]].values\n                y=train[\"outcome\"].values\n\n                f1=[]\n                for train_idx, val_idx in kf.split(X,y):\n                    X_train,y_train=X[train_idx],y[train_idx]\n                    X_val,y_val=X[val_idx],y[val_idx]\n\n                    model = HistGradientBoostingClassifier (max_iter=300, learning_rate=0.02, max_depth=6, random_state=42)\n                    model.fit(X_train,  encode(y_train, target_map))\n                    y_pred = model.predict(X_val)\n                    score = f1_score( encode(y_val, target_map), y_pred, average='micro')\n                    f1.append(score)\n                if f not in best_cols:\n                    scores.append((f,np.mean(f1)))\n            best_col, best_f1=sorted(scores, key=lambda x:x[1], reverse=True)[0]\n            best_cols.append(best_col)\n\n            cols_to_drop = [f for f in correlated_features if  f not in best_cols]\n            if cols_to_drop:\n                final_drop_list=final_drop_list+cols_to_drop\n            table.add_row([col,best_col ,best_f1])\n\nprint(table)      \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Feature Selection","metadata":{}},{"cell_type":"code","source":"final_features=[f for f in train.columns if f not in ['outcome']]\nfinal_features=[*set(final_features)]\nsc=StandardScaler()\n\ntrain_scaled=train.copy()\ntest_scaled=test.copy()\ntrain_scaled[final_features]=sc.fit_transform(train[final_features])\ntest_scaled[final_features]=sc.transform(test[final_features])\n\nX_train = train_scaled[final_features]\ny_train = train['outcome']\n\nX_test = test_scaled[final_features]\n\nprint(X_train.shape, X_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size=\"3\"> More than 100 features got created from the feature engineering, Let's use feature importance from ensemble models to shortlist them. XGBosst, LightGBM, & CatBoost are used </font>","metadata":{}},{"cell_type":"code","source":"def get_most_important_features(X_train, y_train, n,model_input):\n    xgb_params = {\n            'n_estimators': 200,\n            'learning_rate': 0.05,\n            'max_depth': 4,\n            'subsample': 0.8,\n            'colsample_bytree': 0.1,\n            'n_jobs': -1,\n            'eval_metric': 'merror',\n            'objective': 'multi:softprob',\n            'tree_method': 'hist',\n            'verbosity': 0,\n            'random_state': 42,\n        }\n    lgb_params = {\n            'n_estimators': 200,\n            'max_depth': 7,\n            'learning_rate': 0.05,\n            'subsample': 0.20,\n            'colsample_bytree': 0.56,\n            'reg_alpha': 0.25,\n            'reg_lambda': 5e-08,\n            'objective': 'multiclass',\n            'metric': 'multi_logloss',\n            'boosting_type': 'gbdt',\n            'random_state': 42,\n        }\n    cb_params = {\n            'iterations': 200,\n            'depth': 7,\n            'learning_rate': 0.1,\n            'l2_leaf_reg': 0.7,\n            'random_strength': 0.2,\n            'max_bin': 200,\n            'od_wait': 65,\n            'one_hot_max_size': 70,\n            'grow_policy': 'Depthwise',\n            'bootstrap_type': 'Bayesian',\n            'od_type': 'Iter',\n            'eval_metric': 'TotalF1',\n            'loss_function': 'MultiClass',\n            'random_state': 42,\n        }\n    if 'xgb' in model_input:\n        model = xgb.XGBClassifier(**xgb_params)\n    elif 'cat' in model_input:\n        model=CatBoostClassifier(**cb_params)\n    else:\n        model=lgb.LGBMClassifier(**lgb_params)\n        \n    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n    f1_scores = []\n    feature_importances_list = []\n    \n    for train_idx, val_idx in kfold.split(X_train):\n        X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n        y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n\n        model.fit(X_train_fold, encode(y_train_fold,target_map), verbose=False)\n        \n        y_pred = model.predict(X_val_fold)\n        f1_scores.append(f1_score(encode(y_val_fold,target_map), y_pred, average='micro'))\n        feature_importances = model.feature_importances_\n        feature_importances_list.append(feature_importances)\n\n    avg_f1 = np.mean(f1_scores)\n    avg_feature_importances = np.mean(feature_importances_list, axis=0)\n\n    feature_importance_list = [(X_train.columns[i], importance) for i, importance in enumerate(avg_feature_importances)]\n    sorted_features = sorted(feature_importance_list, key=lambda x: x[1], reverse=True)\n    top_n_features = [feature[0] for feature in sorted_features[:n]]\n    \n    display_features=top_n_features[:25]\n    \n    sns.set_palette(\"Set2\")\n    plt.figure(figsize=(8, 15))\n    plt.barh(range(len(display_features)), [avg_feature_importances[X_train.columns.get_loc(feature)] for feature in display_features])\n    plt.yticks(range(len(display_features)), display_features, fontsize=12)\n    plt.xlabel('Average Feature Importance', fontsize=14)\n    plt.ylabel('Features', fontsize=10)\n    plt.title(f'Top {25} of {n} Feature Importances with best F1 score {avg_f1}', fontsize=16)\n    plt.gca().invert_yaxis()  # Invert y-axis to have the most important feature on top\n    plt.grid(axis='x', linestyle='--', alpha=0.7)\n    plt.xticks(fontsize=8)\n    plt.yticks(fontsize=8)\n\n    # Add data labels on the bars\n    for index, value in enumerate([avg_feature_importances[X_train.columns.get_loc(feature)] for feature in display_features]):\n        plt.text(value + 0.005, index, f'{value:.3f}', fontsize=12, va='center')\n\n    plt.tight_layout()\n    plt.show()\n\n    return top_n_features\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_imp_features_cat=get_most_important_features(X_train, y_train,100, 'cat')\nn_imp_features_xgb=get_most_important_features(X_train, y_train,100, 'xgb')\nn_imp_features_lgbm=get_most_important_features(X_train, y_train,100, 'lgbm')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_imp_features=[*set(n_imp_features_xgb+n_imp_features_lgbm+n_imp_features_cat)]\nprint(f\"{len(n_imp_features)} features have been selected from three algorithms for the final model\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train=X_train[n_imp_features]\nX_test=X_test[n_imp_features]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. Modeling","metadata":{}},{"cell_type":"markdown","source":"# 7.1 Class Weights","metadata":{}},{"cell_type":"code","source":"classes = np.unique(y_train)  # Get unique class labels\nclass_to_index = {cls: idx for idx, cls in enumerate(classes)}\ny_train_numeric = np.array([class_to_index[cls] for cls in y_train])\n\nclass_counts = np.bincount(y_train_numeric)\n\ntotal_samples = len(y_train_numeric)\n\nclass_weights = total_samples / (len(classes) * class_counts)\n\nclass_weights_dict = {target_map[cls]: weight for cls, weight in zip(classes, class_weights)}\n\nprint(\"Class counts:\", class_counts)\nprint(\"Total samples:\", total_samples)\nprint(\"Class weights:\", class_weights)\nprint(\"Class weights dictionary:\", class_weights_dict)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size=\"3\"> The modeling section has been adapted from the work of @[tetsutani](https://www.kaggle.com/code/tetsutani/ps3e13-eda-decomposition-ensemble-rankpredict/notebook)</font>","metadata":{}},{"cell_type":"markdown","source":"## 7.2 Models","metadata":{}},{"cell_type":"code","source":"class Splitter:\n    def __init__(self, test_size=0.2, kfold=True, n_splits=5):\n        self.test_size = test_size\n        self.kfold = kfold\n        self.n_splits = n_splits\n\n    def split_data(self, X, y, random_state_list):\n        if self.kfold:\n            for random_state in random_state_list:\n                kf = KFold(n_splits=self.n_splits, random_state=random_state, shuffle=True)\n                for train_index, val_index in kf.split(X, y):\n                    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n                    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n                    yield X_train, X_val, y_train, y_val\n\nclass Classifier:\n    def __init__(self, n_estimators=100, device=\"cpu\", random_state=0):\n        self.n_estimators = n_estimators\n        self.device = device\n        self.random_state = random_state\n        self.models = self._define_model()\n        self.len_models = len(self.models)\n        \n    def _define_model(self):\n        \n        xgb_params = {\n            'n_estimators': self.n_estimators,\n            'learning_rate': 0.05,\n            'max_depth': 4,\n            'subsample': 0.8,\n            'colsample_bytree': 0.1,\n            'n_jobs': -1,\n            'eval_metric': 'merror',\n            'objective': 'multi:softmax',\n            'tree_method': 'hist',\n            'verbosity': 0,\n            'random_state': self.random_state,\n            'class_weight':class_weights_dict,\n        }\n        if self.device == 'gpu':\n            xgb_params['tree_method'] = 'gpu_hist'\n            xgb_params['predictor'] = 'gpu_predictor'\n            \n        xgb_params2=xgb_params.copy()\n        xgb_params2['subsample']=0.7\n        xgb_params2['max_depth']=6\n        \n        lgb_params = {\n            'n_estimators': self.n_estimators,\n            'max_depth': 8,\n            'learning_rate': 0.02,\n            'subsample': 0.20,\n            'colsample_bytree': 0.56,\n            'reg_alpha': 0.25,\n            'reg_lambda': 5e-08,\n            'objective': 'multiclass',\n            'metric': 'multi_logloss',\n            'boosting_type': 'gbdt',\n            'device': self.device,\n            'random_state': self.random_state,\n            'class_weight':class_weights_dict,\n        }\n        lgb_params2 = {\n            'n_estimators': self.n_estimators,\n            'max_depth': 5,\n            'learning_rate': 0.05,\n            'subsample': 0.20,\n            'colsample_bytree': 0.56,\n            'reg_alpha': 0.25,\n            'reg_lambda': 5e-08,\n            'objective': 'multiclass',\n            'metric': 'multi_logloss',\n            'boosting_type': 'gbdt',\n            'device': self.device,\n            'random_state': self.random_state,\n            'class_weight':class_weights_dict,\n        }\n        lgb_params3=lgb_params.copy()\n        lgb_params3['subsample']=0.1\n        lgb_params3['reg_lambda']=0.5940716788024517\n        lgb_params3['reg_alpha']=0.4300477974434703\n        lgb_params3['max_depth']=8\n                \n        cb_params = {\n            'iterations': self.n_estimators,\n            'depth': 6,\n            'learning_rate': 0.05,\n            'l2_leaf_reg': 0.7,\n            'random_strength': 0.2,\n            'max_bin': 200,\n            'od_wait': 65,\n            'one_hot_max_size': 70,\n            'grow_policy': 'Depthwise',\n            'bootstrap_type': 'Bayesian',\n            'od_type': 'Iter',\n            'eval_metric': 'TotalF1',\n            'loss_function': 'MultiClass',\n            'task_type': self.device.upper(),\n            'random_state': self.random_state,\n        }\n        cb_sym_params = cb_params.copy()\n        cb_sym_params['grow_policy'] = 'SymmetricTree'\n        cb_loss_params = cb_params.copy()\n        cb_loss_params['grow_policy'] = 'Lossguide'\n        \n        cb_params2=  cb_params.copy()\n        cb_params2['learning_rate']=0.01\n        cb_params2['depth']=8\n\n        models = {\n            'svc': SVC(gamma=\"auto\", probability=True, random_state=self.random_state),\n            'xgb': xgb.XGBClassifier(**xgb_params),\n            'xgb2': xgb.XGBClassifier(**xgb_params2),\n            'lgb': lgb.LGBMClassifier(**lgb_params),\n            'lgb2': lgb.LGBMClassifier(**lgb_params2),\n            'lgb3': lgb.LGBMClassifier(**lgb_params3),\n            'cat': CatBoostClassifier(**cb_params),\n            \"cat_sym\": CatBoostClassifier(**cb_sym_params),\n            \"cat_loss\": CatBoostClassifier(**cb_loss_params),\n            'cat2': CatBoostClassifier(**cb_params2),\n            'brf': BalancedRandomForestClassifier(n_estimators=4000, n_jobs=-1, random_state=self.random_state),\n            'rf': RandomForestClassifier(n_estimators=1000, random_state=self.random_state),\n            'hist_gbm' : HistGradientBoostingClassifier (max_iter=300, learning_rate=0.02, max_depth=6,class_weight=class_weights_dict, random_state=self.random_state)\n        }\n        \n        return models","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7.3 Optimize Ensemble","metadata":{}},{"cell_type":"code","source":"class OptunaWeights:\n    def __init__(self, random_state, n_trials=5000):\n        self.study = None\n        self.weights = None\n        self.random_state = random_state\n        self.n_trials = n_trials\n\n    def _objective(self, trial, y_true, y_preds):\n        # Define the weights for the predictions from each model\n        weights = [trial.suggest_float(f\"weight{n}\", 1e-12, 2) for n in range(len(y_preds))]\n\n        # Calculate the weighted prediction\n        weighted_pred = np.average(np.array(y_preds), axis=0, weights=weights)\n        \n        weighted_pred_labels = np.argmax(weighted_pred, axis=1)\n        f1_micro_score = f1_score(y_true, weighted_pred_labels, average='micro')\n        return f1_micro_score\n\n    def fit(self, y_true, y_preds):\n        optuna.logging.set_verbosity(optuna.logging.ERROR)\n        sampler = optuna.samplers.CmaEsSampler(seed=self.random_state)\n        pruner = optuna.pruners.HyperbandPruner()\n        self.study = optuna.create_study(sampler=sampler, pruner=pruner, study_name=\"OptunaWeights\", direction='maximize')\n        objective_partial = partial(self._objective, y_true=y_true, y_preds=y_preds)\n        self.study.optimize(objective_partial, n_trials=self.n_trials)\n        self.weights = [self.study.best_params[f\"weight{n}\"] for n in range(len(y_preds))]\n\n    def predict(self, y_preds):\n        assert self.weights is not None, 'OptunaWeights error, must be fitted before predict'\n        weighted_pred = np.average(np.array(y_preds), axis=0, weights=self.weights)\n        return weighted_pred\n\n    def fit_predict(self, y_true, y_preds):\n        self.fit(y_true, y_preds)\n        return self.predict(y_preds)\n    \n    def weights(self):\n        return self.weights","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7.4 Model Fit","metadata":{}},{"cell_type":"code","source":"kfold = True\nn_splits = 1 if not kfold else 5\nrandom_state = 42\nrandom_state_list = [42] \nn_estimators = 9999 \nearly_stopping_rounds = 200\nverbose = False\ndevice = 'cpu'\nsplitter = Splitter(kfold=kfold, n_splits=n_splits)\n\n# Initialize an array for storing test predictions\ntest_predss = np.zeros((X_test.shape[0], 3))\nensemble_score = []\nensemble_f1_score = []\nweights = []\ntrained_models = {'xgb':[], 'lgb':[], 'cat':[]}\n    \nfor i, (X_train_, X_val, y_train_, y_val) in enumerate(splitter.split_data(X_train, y_train, random_state_list=random_state_list)):\n    n = i % n_splits\n    m = i // n_splits\n            \n    # Get a set of Regressor models\n    classifier = Classifier(n_estimators, device, random_state)\n    models = classifier.models\n    \n    # Initialize lists to store oof and test predictions for each base model\n    oof_preds = []\n    test_preds = []\n    \n    # Loop over each base model and fit it to the training data, evaluate on validation data, and store predictions\n    for name, model in models.items():\n        if ('xgb' in name) or ('lgb' in name) or ('cat' in name)  :\n            model.fit(X_train_, encode(y_train_,target_map), eval_set=[(X_val, encode(y_val,target_map))], early_stopping_rounds=early_stopping_rounds, verbose=verbose)\n        else:\n            model.fit(X_train_, encode(y_train_,target_map))\n            \n        if name in trained_models.keys():\n            trained_models[f'{name}'].append(deepcopy(model))\n        \n        test_pred = model.predict_proba(X_test)\n        y_val_pred = model.predict_proba(X_val)\n\n        y_val_pred_labels = np.argmax(y_val_pred, axis=1)\n        f1_micro_score = f1_score(encode(y_val,target_map), y_val_pred_labels, average='micro')\n        \n        score = log_loss(encode(y_val,target_map), y_val_pred)\n        print(f'{name} [FOLD-{n} SEED-{random_state_list[m]}] F1 Micro Score: {f1_micro_score:.5f}, Logloss: {score:.5f}')\n        \n        oof_preds.append(y_val_pred)\n        test_preds.append(test_pred)\n    \n    # Use Optuna to find the best ensemble weights\n    optweights = OptunaWeights(random_state=random_state)\n    y_val_pred = optweights.fit_predict(encode(y_val,target_map), oof_preds)\n    \n    score = log_loss(encode(y_val,target_map), y_val_pred)\n    y_val_pred_labels = np.argmax(y_val_pred, axis=1)\n    f1_micro_score = f1_score(encode(y_val,target_map), y_val_pred_labels, average='micro')\n    \n    print(f'Ensemble [FOLD-{n} SEED-{random_state_list[m]}] ---------------> F1 Micro Score: {f1_micro_score:.5f}, Logloss: {score:.5f}')\n    \n    ensemble_score.append(score)\n    ensemble_f1_score.append(f1_micro_score)\n    weights.append(optweights.weights)\n    \n    # Predict to X_test by the best ensemble weights\n    _test_preds = optweights.predict(test_preds)\n    test_predss += _test_preds / (n_splits * len(random_state_list))\n    \n    gc.collect()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the mean LogLoss score of the ensemble\nmean_score = np.mean(ensemble_f1_score)\nstd_score = np.std(ensemble_f1_score)\nprint(f'Ensemble F1 score {mean_score:.5f} ± {std_score:.5f}')\n\n# Print the mean and standard deviation of the ensemble weights for each model\nprint('--- Model Weights ---')\nmean_weights = np.mean(weights, axis=0)\nstd_weights = np.std(weights, axis=0)\nfor name, mean_weight, std_weight in zip(models.keys(), mean_weights, std_weights):\n    print(f'{name}: {mean_weight:.5f} ± {std_weight:.5f}')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7.5 Feature Importance Visualization","metadata":{}},{"cell_type":"code","source":"def visualize_importance(models, feature_cols, title, head=15):\n    importances = []\n    feature_importance = pd.DataFrame()\n    for i, model in enumerate(models):\n        _df = pd.DataFrame()\n        _df[\"importance\"] = model.feature_importances_\n        _df[\"feature\"] = pd.Series(feature_cols)\n        _df[\"fold\"] = i\n        _df = _df.sort_values('importance', ascending=False)\n        _df = _df.head(head)\n        feature_importance = pd.concat([feature_importance, _df], axis=0, ignore_index=True)\n        \n    feature_importance = feature_importance.sort_values('importance', ascending=False)\n    # display(feature_importance.groupby([\"feature\"]).mean().reset_index().drop('fold', axis=1))\n    plt.figure(figsize=(18, 10))\n    sns.barplot(x='importance', y='feature', data=feature_importance, color= (0.4, 0.76, 0.65), errorbar='sd')\n    plt.xlabel('Importance', fontsize=14)\n    plt.ylabel('Feature', fontsize=14)\n    plt.title(f'{title} Feature Importance', fontsize=18)\n    plt.grid(True, axis='x')\n    plt.show()\n    \nfor name, models in trained_models.items():\n    visualize_importance(models, list(X_train.columns), name)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7.6 Submission","metadata":{}},{"cell_type":"code","source":"sub = pd.read_csv('/kaggle/input/playground-series-s3e22/sample_submission.csv')\nsub['outcome'] =  decode(np.argmax(test_predss, axis=1),target_map)\nsub.to_csv('submission.csv',index=False)\nsub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8. Further Scope of Improvement?","metadata":{}},{"cell_type":"markdown","source":"* Tune Hyper-parameters \n* Improve Feature Selection\n* A better strategy to combine predictions using Optuna","metadata":{}}]}