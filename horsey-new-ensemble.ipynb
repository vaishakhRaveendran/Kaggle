{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/vaishakhraveendran/horsey-new-ensemble?scriptVersionId=144025585\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy import stats\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-24T04:27:54.009629Z","iopub.execute_input":"2023-09-24T04:27:54.01Z","iopub.status.idle":"2023-09-24T04:27:55.111075Z","shell.execute_reply.started":"2023-09-24T04:27:54.009972Z","shell.execute_reply":"2023-09-24T04:27:55.110013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nimport pandas as pd\n\nclass ReduceDim:\n    def __init__(self, n):\n        self.n = n\n        self.pca = PCA(n_components=n)\n\n    def fit_transform(self, M):\n        M_ = self.pca.fit_transform(M)\n        M = pd.concat([M, pd.DataFrame(M_, columns=[f'PCA{i+1}' for i in range(self.n)])], axis=1)\n        return M\n\n    def transform(self, N):\n        N_ = self.pca.transform(N)\n        N = pd.concat([N, pd.DataFrame(N_, columns=[f'PCA{i+1}' for i in range(self.n)])], axis=1)\n        return N","metadata":{"execution":{"iopub.status.busy":"2023-09-24T04:27:55.112919Z","iopub.execute_input":"2023-09-24T04:27:55.113362Z","iopub.status.idle":"2023-09-24T04:27:55.468187Z","shell.execute_reply.started":"2023-09-24T04:27:55.113317Z","shell.execute_reply":"2023-09-24T04:27:55.467235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Model Imports\nfrom sklearn.metrics import f1_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn import preprocessing","metadata":{"execution":{"iopub.status.busy":"2023-09-24T04:27:55.469571Z","iopub.execute_input":"2023-09-24T04:27:55.469879Z","iopub.status.idle":"2023-09-24T04:27:55.681091Z","shell.execute_reply.started":"2023-09-24T04:27:55.469853Z","shell.execute_reply":"2023-09-24T04:27:55.679831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Correlation plots\ndef plot_heatmap(df, title):\n    # Create a mask for the diagonal elements\n    df=df.drop([target_col],axis=1)\n    df=df[num_cols]\n    mask = np.zeros_like(df.astype(float).corr())\n    mask[np.triu_indices_from(mask)] = True\n\n    # Set the colormap and figure size\n    colormap = plt.cm.RdBu_r\n    plt.figure(figsize=(16, 16))\n\n    # Set the title and font properties\n    plt.title(f'{title} Correlation of Features', fontweight='bold', y=1.02, size=20)\n\n    # Plot the heatmap with the masked diagonal elements\n    sns.heatmap(df.astype(float).corr(), linewidths=0.1, vmax=1.0, vmin=-1.0, \n                square=True, cmap=colormap, linecolor='white', annot=True, annot_kws={\"size\": 14, \"weight\": \"bold\"},\n                mask=mask)","metadata":{"execution":{"iopub.status.busy":"2023-09-24T04:27:55.683453Z","iopub.execute_input":"2023-09-24T04:27:55.683767Z","iopub.status.idle":"2023-09-24T04:27:55.692056Z","shell.execute_reply.started":"2023-09-24T04:27:55.683739Z","shell.execute_reply":"2023-09-24T04:27:55.690698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def df_Impute(df):\n    df['pain'] = df['pain'].fillna('depressed')\n    df['abdomo_protein'] = df['abdomo_protein'].fillna(3.5)\n    df['rectal_exam_feces'] = df['rectal_exam_feces'].fillna('absent')\n    df['abdomen'] = df['abdomen'].fillna('distend_small')\n    df['packed_cell_volume'] = df['packed_cell_volume'].fillna(49)\n    df['total_protein'] = df['total_protein'].fillna(7.5)\n    df['peristalsis'] = df['peristalsis'].fillna('hypomotile')\n    df['abdominal_distention'] = df['abdominal_distention'].fillna('moderate')\n    df['nasogastric_tube'] = df['nasogastric_tube'].fillna('slight')\n    df['nasogastric_reflux'] = df['nasogastric_reflux'].fillna('none')\n    df['nasogastric_reflux_ph'] = df['nasogastric_reflux_ph'].fillna(4.3)\n    df['rectal_temp'] = df['rectal_temp'].fillna(38.0)\n    df['pulse'] = df['pulse'].fillna(78)\n    df['respiratory_rate'] = df['respiratory_rate'].fillna(30)\n    df['temp_of_extremities'] = df['temp_of_extremities'].fillna('cool')\n    df['peripheral_pulse'] = df['peripheral_pulse'].fillna('normal')\n    df['mucous_membrane'] = df['mucous_membrane'].fillna('pale_pink')\n    df['capillary_refill_time'] = df['capillary_refill_time'].fillna('less_3_sec')\n    return df\n","metadata":{"execution":{"iopub.status.busy":"2023-09-24T04:27:55.6933Z","iopub.execute_input":"2023-09-24T04:27:55.693617Z","iopub.status.idle":"2023-09-24T04:27:55.709165Z","shell.execute_reply.started":"2023-09-24T04:27:55.693592Z","shell.execute_reply":"2023-09-24T04:27:55.708388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def feature_eng(df_):\n    df_['rectal_temp']=df_['rectal_temp'].apply(lambda x:abs(x-37.8))\n    df_['log_pulse']=np.log1p(df_['pulse'])\n    df_['sqrt_total_protein']=np.sqrt(df_['total_protein'])\n    df_['log_respiratory_rate']=np.log1p(df_['respiratory_rate'])\n    df_['log_lesion_1']=np.log1p(df_['lesion_1'])\n    df_['sqrt_abdomo_protein']=np.sqrt(df_['abdomo_protein'])\n    df_['log_nasogastric_reflux_ph']=np.log1p(X['nasogastric_reflux_ph'])\n    # Replace specific values for certain columns\n    replace_values = {\n        \"pain\": {'slight': 'moderate'},\n        \"peristalsis\": {'distend_small': 'normal'},\n        \"rectal_exam_feces\": {'serosanguious': 'absent'},\n        \"nasogastric_reflux\": {'slight': 'none'}\n    }\n    df_.replace(replace_values, inplace=True)\n    return df_","metadata":{"execution":{"iopub.status.busy":"2023-09-24T04:27:55.710273Z","iopub.execute_input":"2023-09-24T04:27:55.710599Z","iopub.status.idle":"2023-09-24T04:27:55.723241Z","shell.execute_reply.started":"2023-09-24T04:27:55.710572Z","shell.execute_reply":"2023-09-24T04:27:55.722126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#warning suppress\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.filterwarnings(\"ignore\")\n#Ensembling\nfrom scipy import stats as st\ndef fold(fold_list,K):\n    stack=np.column_stack((fold_list[i] for i in range(K)))\n    mode=st.mode(stack,axis=1)\n    return mode[0]","metadata":{"execution":{"iopub.status.busy":"2023-09-24T04:27:55.72455Z","iopub.execute_input":"2023-09-24T04:27:55.725333Z","iopub.status.idle":"2023-09-24T04:27:55.738657Z","shell.execute_reply.started":"2023-09-24T04:27:55.725305Z","shell.execute_reply":"2023-09-24T04:27:55.737847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Category encoder\nfrom category_encoders import OrdinalEncoder\ndef cat_encoder(X_train, X_test, cat_cols):\n        encoder = OrdinalEncoder(cols=cat_cols, handle_missing='ignore')\n        train_encoder = encoder.fit_transform(X_train[cat_cols]).astype(int)\n        test_encoder = encoder.transform(X_test[cat_cols]).astype(int)\n        X_train[cat_cols] = train_encoder[cat_cols]\n        X_test[cat_cols] = test_encoder[cat_cols]\n        encoder_cols = cat_cols\n        return X_train, X_test, encoder_cols","metadata":{"execution":{"iopub.status.busy":"2023-09-24T04:27:55.739522Z","iopub.execute_input":"2023-09-24T04:27:55.739821Z","iopub.status.idle":"2023-09-24T04:27:56.176507Z","shell.execute_reply.started":"2023-09-24T04:27:55.739795Z","shell.execute_reply":"2023-09-24T04:27:56.175537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_map(df_train,catCols,n_cols=2):\n    n_rows=(len(catCols))//n_cols\n    fig, axes = plt.subplots(n_rows,n_cols,figsize=(18,6*n_rows))\n    ax=axes.flatten()\n    for i,col in enumerate(catCols):\n        if col !=target_col:\n            sns.heatmap(data = pd.crosstab(df_train[col], df_train[target_col]),\n                    annot = True, fmt = '.0f', ax = ax[i])\n            ax[i].set_title(f'{col} Distribution (Train)')","metadata":{"execution":{"iopub.status.busy":"2023-09-24T04:27:56.177779Z","iopub.execute_input":"2023-09-24T04:27:56.178107Z","iopub.status.idle":"2023-09-24T04:27:56.185587Z","shell.execute_reply.started":"2023-09-24T04:27:56.178078Z","shell.execute_reply":"2023-09-24T04:27:56.184124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_hist(df_train,df_test,numCols,n_cols=2):\n    n_rows=(len(numCols)-1)//n_cols\n    fig, axes = plt.subplots(n_rows,n_cols,figsize=(18,6*n_rows))\n    ax=axes.flatten()\n    numCols.remove('hospital_number')\n    for i,col in enumerate(numCols):\n            sns.histplot(df_train[col],ax=ax[i],kde=True)\n            sns.histplot(df_test[col],ax=ax[i],kde=True)\n            ax[i].set_title(f'{col} Distribution (Train v/s Test)')\n            ","metadata":{"execution":{"iopub.status.busy":"2023-09-24T04:27:56.190387Z","iopub.execute_input":"2023-09-24T04:27:56.190845Z","iopub.status.idle":"2023-09-24T04:27:56.203442Z","shell.execute_reply.started":"2023-09-24T04:27:56.190805Z","shell.execute_reply":"2023-09-24T04:27:56.202429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FILEPATH ='/kaggle/input/playground-series-s3e22'\n#Reading the train and test sets and joining\ndf_train=pd.read_csv(os.path.join(FILEPATH,'train.csv')).set_index('id')\ndf_test=pd.read_csv(os.path.join(FILEPATH,'test.csv')).set_index('id')\ndf_original=pd.read_csv('/kaggle/input/horse-survival-dataset/horse.csv')\nindexx=np.arange(df_train.index[-1]+1, df_train.index[-1] + df_original.shape[0]+1)\ndf_original.index=indexx\ndf_train=pd.concat([df_train,df_original],axis=0).sample(frac = 1)\n\n\n#Defining categorical and numerical columns\ndf_train['hospital_number']=df_train['hospital_number'].astype('object')\ndf_test['hospital_number']=df_test['hospital_number'].astype('object')\ncat_cols=df_train.select_dtypes(include='object').columns.to_list()[:-1]\nnum_cols=df_train.select_dtypes(include=['int64','float64']).columns.to_list()\ntarget_col='outcome'\n\n#checking null columns\n#df_train.isna().sum(),df_test.isna().sum()\n#Columns with null values\nnull_columns=[ 'pain','abdomo_protein','rectal_exam_feces','abdomen','packed_cell_volume',\n              'total_protein','peristalsis' ,'abdominal_distention','nasogastric_tube',\n              'nasogastric_reflux','nasogastric_reflux_ph','rectal_temp','pulse','respiratory_rate',\n              'temp_of_extremities','peripheral_pulse','mucous_membrane','capillary_refill_time']","metadata":{"execution":{"iopub.status.busy":"2023-09-24T04:27:56.204806Z","iopub.execute_input":"2023-09-24T04:27:56.205186Z","iopub.status.idle":"2023-09-24T04:27:56.375922Z","shell.execute_reply.started":"2023-09-24T04:27:56.205156Z","shell.execute_reply":"2023-09-24T04:27:56.374718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Data preprocessing\nX= df_train.drop([f'{target_col}'],axis=1).reset_index(drop=True)\ny = df_train[[f'{target_col}']].reset_index(drop=True)\nX_=df_test.copy().reset_index(drop=True)\n\n#imputation\n# X_train=df_Impute(X_train)\n# X_test=df_Impute(X_test)\n\n#category_encoding\nX, X_, cat_cols = cat_encoder(X, X_, cat_cols)\ny['outcome']= y['outcome'].map({'died':0,'euthanized':1,'lived':2})\n\n#Drop columns\ndrop_cols = ['lesion_3','lesion_2']\nX.drop(drop_cols, axis=1, inplace=True)\nX_.drop(drop_cols, axis=1, inplace=True)\n\n#Filling the null values and standard scaling is essential for tensorflow.\nfrom sklearn.impute import KNNImputer\nimputer = KNNImputer(n_neighbors=10)\nX=pd.DataFrame(imputer.fit_transform(X),index=X.index,columns=X.columns)\nX_=pd.DataFrame(imputer.transform(X_),index=X_.index,columns=X_.columns)\n# X=X.fillna(0)\n# X_=X_.fillna(0)","metadata":{"execution":{"iopub.status.busy":"2023-09-24T04:27:56.377276Z","iopub.execute_input":"2023-09-24T04:27:56.37761Z","iopub.status.idle":"2023-09-24T04:27:56.605454Z","shell.execute_reply.started":"2023-09-24T04:27:56.377583Z","shell.execute_reply":"2023-09-24T04:27:56.604191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Feature engineering\nX=feature_eng(X)\nX_=feature_eng(X_)\n\n#Dimensionality reduction\ndim=ReduceDim(2)\nX=dim.fit_transform(X)\nX_=dim.transform(X_)\n\n#visualise dimensionality reduction\nM=pd.concat([X,y],axis=1)\nsns.scatterplot(data=M, x=\"PCA1\", y=\"PCA2\", hue=f\"{target_col}\") \n\n#feature scaling\nscale=preprocessing.StandardScaler()\nX=pd.DataFrame(scale.fit_transform(X),index=X.index,columns=X.columns)\nX_=pd.DataFrame(scale.transform(X_),index=X_.index,columns=X_.columns)","metadata":{"execution":{"iopub.status.busy":"2023-09-24T04:27:56.607568Z","iopub.execute_input":"2023-09-24T04:27:56.608463Z","iopub.status.idle":"2023-09-24T04:27:57.255592Z","shell.execute_reply.started":"2023-09-24T04:27:56.60842Z","shell.execute_reply":"2023-09-24T04:27:57.254601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# transform the dataset to be more balanced.\nfrom imblearn.over_sampling import SMOTE\noversample = SMOTE()\nX, y = oversample.fit_resample(X, y)","metadata":{"execution":{"iopub.status.busy":"2023-09-24T04:27:57.257251Z","iopub.execute_input":"2023-09-24T04:27:57.257598Z","iopub.status.idle":"2023-09-24T04:27:57.519767Z","shell.execute_reply.started":"2023-09-24T04:27:57.257569Z","shell.execute_reply":"2023-09-24T04:27:57.518808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nimport tensorflow as tf\nfrom tensorflow.keras import regularizers\n\nfrom tensorflow import keras\nearly_stopping = keras.callbacks.EarlyStopping(\n    patience=15,\n    min_delta=0.001,\n    restore_best_weights=True,\n)\n\n#It is better to reduce the learning rate as we do training.\nlr_schedule = keras.optimizers.schedules.InverseTimeDecay(\n  0.001,\n  decay_steps=X.shape[0]*20,\n  decay_rate=1,\n  staircase=False)\n\ndef tf_model():\n    model_tf=tf.keras.Sequential([\n        keras.layers.Input(shape=[33,]),\n        keras.layers.Dense(256, activation='relu',kernel_regularizer=regularizers.l2(0.003)),\n        keras.layers.Dropout(0.2),\n        keras.layers.Dense(128, activation='relu',kernel_regularizer=regularizers.l2(0.003),),\n        keras.layers.Dropout(0.2),\n        keras.layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001),),\n        keras.layers.Dense(8, activation='relu'),\n        keras.layers.Dropout(0.2),\n        keras.layers.Dense(3, activation='softmax')])\n        \n    model_tf.compile(optimizer= keras.optimizers.Adam(lr_schedule),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n    return model_tf\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-24T04:27:57.521002Z","iopub.execute_input":"2023-09-24T04:27:57.52145Z","iopub.status.idle":"2023-09-24T04:28:06.175641Z","shell.execute_reply.started":"2023-09-24T04:27:57.521419Z","shell.execute_reply":"2023-09-24T04:28:06.174452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"####################### XGB CLASSSIFIER #######################\nfrom xgboost import XGBClassifier\ndef xgb_model():\n    xgb_params = {\n        'n_estimators': 5000,\n        'n_jobs': -1,\n        'max_depth': 5,\n        'eta': 0.2,\n        'colsample_bytree': 0.8,\n        'objective': 'multi:softprob',\n        'num_class': 3,\n        'alpha': 8e-07,\n        'lambda': 0.0012,\n        'early_stopping_rounds':10,\n        'verbose':10\n        }\n    return XGBClassifier(**xgb_params)\n######################## Naive Bayes ##############\nfrom sklearn.naive_bayes import MultinomialNB\ndef naive_model():\n    naive_params={\n        \n    }\n    return MultinomialNB(**naive_params)\n################## LDA #############################\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\ndef lad_model():\n    return LinearDiscriminantAnalysis()\n \n################## LGBM CLASSIFIER ############################\nfrom lightgbm import LGBMClassifier\ndef lgbm_model():\n    lgb_params= {\n            'objective': 'multiclass',\n            'metric': 'auc_mu', \n            'num_class': 3,\n            'feature_pre_filter': False, \n            'lambda_l1': 1.0309196948445505e-05,\n            'lambda_l2': 0.034674458424846455, \n            'num_leaves': 52,\n            'feature_fraction': 0.8480000000000001,\n            'bagging_fraction': 0.9622932514137276, \n            'bagging_freq': 6, \n            'min_child_samples': 20, \n            'num_iterations': 50,\n            'early_stopping_round': None\n         \n        }\n    return LGBMClassifier(**lgb_params)\n    \n####################### CATBOOST CLASSIFIER ###############\nfrom catboost import CatBoostClassifier \ndef cat_model():\n    cat_params = {\n        'depth': 6,\n        'learning_rate': 0.05,\n        'l2_leaf_reg': 0.7,\n        'random_strength': 0.2,\n        'max_bin': 200,\n        'od_wait': 65,\n        'one_hot_max_size': 70,\n        'grow_policy': 'Depthwise',\n        'bootstrap_type': 'Bayesian',\n        'od_type': 'Iter',\n        'eval_metric': 'TotalF1',\n        'loss_function': 'MultiClass',\n        }\n    return CatBoostClassifier(**cat_params)\n\n\n############## RANDOM FOREST ########\nfrom sklearn.ensemble import RandomForestClassifier\ndef forest_model():\n    return RandomForestClassifier()\n\n############## HIST CLASSIFIER\nfrom sklearn.ensemble import HistGradientBoostingClassifier\ndef hist_model():\n    hist_params = {\n            'l2_regularization': 0.1,\n            'early_stopping': True,\n            'learning_rate': 0.1,\n            'max_iter': 80,\n            'max_depth': 4,\n            'scoring':'f1_micro',\n            'max_bins': 255,\n            'min_samples_leaf': 10,\n            'max_leaf_nodes':21,\n            'class_weight':'balanced',\n            'random_state': 42\n        }\n    return HistGradientBoostingClassifier(**hist_params)\n########## ADA BOOST CLASSIFIER #############\nfrom sklearn.ensemble import AdaBoostClassifier\ndef ada_model():\n    return AdaBoostClassifier()","metadata":{"execution":{"iopub.status.busy":"2023-09-24T04:28:06.177552Z","iopub.execute_input":"2023-09-24T04:28:06.178448Z","iopub.status.idle":"2023-09-24T04:28:07.646266Z","shell.execute_reply.started":"2023-09-24T04:28:06.1784Z","shell.execute_reply":"2023-09-24T04:28:07.645368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking for optimal transformation.\n# t = np.sqrt(X['lesion_1'])\n# sns.histplot(x=t, kde=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-24T04:28:07.647466Z","iopub.execute_input":"2023-09-24T04:28:07.647789Z","iopub.status.idle":"2023-09-24T04:28:07.651655Z","shell.execute_reply.started":"2023-09-24T04:28:07.647762Z","shell.execute_reply":"2023-09-24T04:28:07.650808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualising numerical columns\nfig,axs=plt.subplots(2, 2, figsize=(10, 2*5))\nax=axs.flatten()\nfor i,col in enumerate(['total_protein','nasogastric_reflux_ph','pulse','lesion_1']):\n    sns.histplot(x=X[col],kde=True,ax=ax[i])\nplt.tight_layout","metadata":{"execution":{"iopub.status.busy":"2023-09-24T04:28:07.653Z","iopub.execute_input":"2023-09-24T04:28:07.653302Z","iopub.status.idle":"2023-09-24T04:28:09.388698Z","shell.execute_reply.started":"2023-09-24T04:28:07.653275Z","shell.execute_reply":"2023-09-24T04:28:09.387857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# eval_set=[(X_val, y_val)]\nn_split=12\nrandom_state=42\npreds=pd.DataFrame()\nkf = StratifiedKFold(n_splits=n_split, random_state=random_state, shuffle=True)\nfor i,(train_index, val_index) in enumerate(kf.split(X,y)):\n    models={}\n    class_probs={}\n    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n    \n    ###########Deep Neural_MODEL###################\n    y_train, y_val = [tf.keras.utils.to_categorical(y.iloc[index]) for index in [train_index, val_index]]\n    model=tf_model()\n    model.fit(X_train,y_train,validation_data=[X_val,y_val],epochs=1,\n                    callbacks=[early_stopping],batch_size=200)\n    models['tf_model']=model\n    \n    ######Non Neural Neural Networks#######################\n    y_train, y_val = y.iloc[train_index],y.iloc[val_index]\n    ###XGB classifier ########\n    model=xgb_model()\n    model.fit(X_train, y_train,eval_set=[(X_val,y_val)])\n    models['xgb_model']=model\n    ####LGBM classifier########\n    model=lgbm_model()\n    model.fit(X_train, y_train,eval_set=[(X_val,y_val)])\n    models['lgbm_model']=model\n    ####CAT classifier########\n    model=cat_model()\n    model.fit(X_train, y_train,eval_set=[(X_val,y_val)])\n    models['cat_model']=model\n    ####### RANDOM FOREST ####\n    model=forest_model()\n    model.fit(X_train,y_train)\n    models['forest_model']=model\n    ######### HIST GRAD#######\n    model=hist_model()\n    model.fit(X_train,y_train)\n    models['hist_model']=model\n    ######### ADA M0DEL #######\n    model=ada_model()\n    model.fit(X_train,y_train)\n    models['ada_model']=model\n    \n    #####Ensemble Models#######################\n    for model_name, model in models.items():\n        if model_name =='tf_model':\n             probs = model.predict(X_)\n        else :\n            probs=model.predict_proba(X_)\n        class_probs[model_name] = probs\n        #print(f'{model_name}: {f1_score(y_val, model.predict(X_val), average=\"micro\")}')\n    ensemble_probs = np.mean(list(class_probs.values()), axis=0)\n    probs= np.argmax(ensemble_probs, axis=1)\n    preds.insert(loc=0, column=f'fold_{i+1}', value=probs)\n    \n    print(f'############## FOLD{i+1}########################')","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-09-24T04:28:09.390131Z","iopub.execute_input":"2023-09-24T04:28:09.390719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy import stats as st\npreds['mode']=preds.apply(lambda x:st.mode(x)[0],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig, axs=plt.subplots(3,2,figsize=(12, 5*2))\nax=axs.flatten()\nfor i,model in enumerate(['xgb_model','cat_model','lgbm_model','forest_model','ada_model']):\n    feat_imp = pd.Series(models[model].feature_importances_, index=X.columns)\n    ax[i].set_title(f'Feature_Importance_{model}')\n    feat_imp.nlargest(10).plot(kind='barh',ax=ax[i])\n    plt.xticks(rotation=45)\n    \nplt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission=pd.read_csv(os.path.join(FILEPATH,'sample_submission.csv')).set_index('id')\ndf_submission['outcome']=np.array(preds['mode'])\ndf_submission['outcome']=df_submission['outcome'].map({0:'died',1:'euthanized',2:'lived'})\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission.to_csv('submission_slay_kill_monster.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}